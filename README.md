# Assistant IA RAG interne ‚Äì Projet 1

> **J‚Äôai d√©velopp√© hier en 2h un chatbot IA √† la Gare du Nord.**  
> Ce repo contient la version propre de ce projet. üéØ

##  Contexte

L‚Äôobjectif de ce projet est de construire un **assistant IA interne** capable de :

- Lire des documents internes (PDF / TXT)
- Indexer leur contenu de fa√ßon s√©mantique
- R√©pondre aux questions des collaborateurs
- Citer les documents sources utilis√©s

C‚Äôest un cas d‚Äôusage typique des grands groupes qui cherchent √† transformer leur documentation en copilote intelligent pour les √©quipes (RH, IT, support, etc.).

##  Stack technique

- **Python** (Google Colab)
- **OpenAI API**
  - `text-embedding-3-small` pour les embeddings
  - `gpt-4.1-mini` pour la g√©n√©ration de r√©ponses
- **FAISS** : index vectoriel pour la recherche s√©mantique
- **LangChain** : chunking avanc√© des documents
- **PyPDF / pypdf** : extraction de texte depuis les PDF
- **Gradio** : interface chat type ‚Äúassistant interne‚Äù


##  Architecture du syst√®me

1. **Ingestion des documents**
   - Upload de fichiers `.pdf` ou `.txt`
   - Extraction du texte
2. **Pr√©paration / Chunking**
   - D√©coupage en morceaux de ~800 caract√®res avec overlap
   - Chunking ‚Äúintelligent‚Äù via `RecursiveCharacterTextSplitter`
3. **Indexation**
   - Calcul des embeddings (OpenAI)
   - Normalisation et stockage dans un index FAISS
   - Cache des embeddings et des m√©tadonn√©es (`faiss_index.bin`, `chunks_meta.json`)
4. **Retrieval + Reranking**
   - Embedding de la question
   - Recherche des `top_k` passages via FAISS
   - Reranking l√©ger via LLM pour garder les passages les plus pertinents
5. **G√©n√©ration de r√©ponse (RAG)**
   - Construction d‚Äôun CONTEXTE √† partir des meilleurs chunks
   - Prompt avec guardrails :
     - ne r√©pondre que sur la base du contexte
     - signaler si l‚Äôinfo n‚Äôest pas disponible
6. **Interface utilisateur**
   - Chat Gradio (`gr.ChatInterface`)
   - Historique des √©changes
   - Affichage des sources utilis√©es

##  Utilisation (version Colab)

1. Ouvrir le notebook :

```text
notebooks/assistant_rag_gare_du_nord.ipynb
Renseigner sa cl√© API OpenAI dans la cellule pr√©vue.

2. Ex√©cuter les cellules dans l‚Äôordre :

3. installation des d√©pendances

4. configuration client OpenAI

5. ingestion des documents

6. construction / chargement de l‚Äôindex FAISS

7. lancement de l‚Äôinterface Gradio

8. Uploader des documents internes (proc√©dures, notes, etc.)

9. Poser des questions dans l‚Äôinterface chat.
